{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5mk+MqpI/tgdQu8uSje6u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleasewaitinthequeue/sqlglot-lightning-talk/blob/main/sqlglot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem\n",
        "\n",
        "I am tired of my old database and it costs too much.  I want to migrate to another type of database that is \"better\" for my business.  I have a bunch of SQL code from the old database, and I want to migrate it to another database.  How do I **translate** the code from **SQL Dialect A** ==> **SQL Dialect B**?\n",
        "\n",
        "## What is a Dialect\n",
        "Some of you are wondering what the heck I mean by dialect.  SQL is a standard right?  Shouldn't it be the same everywhere?\n",
        "\n",
        "**ANSI-SQL** is a standard, but databases are usually paid products, and so software companies have a financial incentive to make their database do special things that are exclusive to that database.  Most databases will compile ANSI-SQL, but each database has expressions, functions, procedures, and flavor that is unique to that database.  Therefore, the syntax that each database accepts often needs to be specific to the brand of database.  Some brands lean heavily into custom syntax while others use the ANSI-SQL syntax, but have custom functions.  Some widely used SQL dialects are:  \n",
        "* Microsoft = Transact-SQL (T-SQL)\n",
        "* MySQL / MariaDB / PostgreSQL = (ANSI-SQL)\n",
        "* Oracle = Procedural Language-SQL (PL-SQL)\n",
        "\n",
        "*there are some really popular \"Not Only SQL\" databases that I left off of here for brevity [source](https://www.bairesdev.com/blog/most-popular-databases/)\n",
        "\n",
        "## Solutions\n",
        "* Burn Old DB Down and Build a New DB\n",
        "* Go through the SQL code line by line Finding / Replacing keywords that aren't compatible\n",
        "* Hire Consultants / Outsource\n",
        "* Ask ChatGPT / Gemini / CoPilot\n",
        "* Write a Python Program Leveraging existing Libraries\n",
        "\n",
        "| Option | Pros | Cons |\n",
        "| ------ | ------ | ------ |\n",
        "| Burn it Down | Start Fresh | Lose Data?!!!! |\n",
        "| Edit Code | Precise | Time Consuming |\n",
        "| Hire Consultants | Quick | Expensive |\n",
        "| Ask LLMs | Free or Cheap | Lacks Precision / Context |\n",
        "| Write Python | Free or Cheap | Limits to Precision / Context |\n"
      ],
      "metadata": {
        "id": "cQNWM4WlLQfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Handful of Options\n",
        "* sqlparse - (IR 2009) - non validating sql **parser** that does not understand dialects\n",
        "* sqlfluff - (IR 2018) - dialect-flexible **parser/linter**\n",
        "* sqlglot - (IR 2021) - **parser, transpiler, and optimizer** with dialect support\n",
        "* sqltree - (In Development) - **parser/formatter** that supports limited dialects\n",
        "\n",
        "Eliza Pan - 05/10/2023 - Open-source Python SQL parsers [(on Medium.com)](https://medium.com/@elizapan/open-source-python-sql-parsers-8dcfaf0c896a)\n",
        "She has a series of articles on medium describing migration from Amazon Redshift to Trino DB (both are distributed No-SQL databases).  She leveraged **sqlglot** to help with these tasks."
      ],
      "metadata": {
        "id": "ip_0dVF4QoVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL Glot\n",
        "\n",
        "SQLGlot is a no-dependency SQL parser, transpiler, optimizer, and engine. It can be used to format SQL or translate between 24 different dialects like DuckDB, Presto / Trino, Spark / Databricks, Snowflake, and BigQuery. It aims to read a wide variety of SQL inputs and output syntactically and semantically correct SQL in the targeted dialects.\n",
        "* Project Website: https://sqlglot.com/sqlglot.html\n",
        "* Code Repository: https://github.com/tobymao/sqlglot\n",
        "* LinkedIn: https://www.linkedin.com/in/toby-mao/\n",
        "\n",
        "## SQLglot is pythonic!?\n",
        "**Mostly**....Lower level components such as the tokenization are handled by RUST.  According to github, rust accounts for 1.3% of the code or 6 files within this library at the time of writing.  RUST is mainly used during the tokenization / parsing process."
      ],
      "metadata": {
        "id": "9nYRTu4KkMN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toby [Tobias] Mao [bio](https://g.co/kgs/2NVAz8D):\n",
        "* Born 1988\n",
        "* Hillsborough, CA\n",
        "* B.A. in Computer Science from Northwestern University in 2011\n",
        "* Number of jobs working at Tech firms since then.  Notably Netflix and AirBnB prior to founding his own analytics firm called [Tobiko Data](https://tobikodata.com/)\n",
        "\n",
        "It was at these companies that he likely wanted to rip his own hair out working with all of the different types of databases.  Netflix and AirBnB leverage a number of traditional rdbms as well as no-sql databases.  Tobiko Data offers a cloud data management solution similar to DBT promising cloud based ETL/ELT.  Tag lines from his company's website follow:\n",
        "\n",
        "> ### Meet Tobiko Cloud: data transformation without the waste.\n",
        "> #### It's everything dbt™ wishes it was.\n",
        "> *Tobiko Cloud is powered by SQLMesh to parse SQL and track column-level lineage. Instantly see the impact of your changes, and run only the updates you need.*\n",
        "\n"
      ],
      "metadata": {
        "id": "ZuUXHxmJlVte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[SQLmesh](https://sqlmesh.readthedocs.io/en/stable/) is a next-generation data transformation framework designed to ship data quickly, efficiently, and without error. Data teams can efficiently run and deploy data transformations written in SQL or Python with visibility and control at any size.\n",
        "\n",
        "[Diagram](https://github.com/TobikoData/sqlmesh/blob/main/docs/readme/architecture_diagram.png?raw=true)"
      ],
      "metadata": {
        "id": "qZO0tg0YuToR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's back up to SQL Glot though and discuss:\n",
        "Just what is a \"Transpiler\"?  And why do you need one?\n",
        "\n",
        "The word itself \"Transpile\" is related to the word Compile.  \n",
        "\n",
        "SQL or **Structured Query Language** goes back to the early days of computing.  Although ANSI-SQL is a standard that most all databases conform to, each database has flavor and smell to their syntax that while similar - it is difficult to take a query from one database and run it on another."
      ],
      "metadata": {
        "id": "4BNEG_ZjrRNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason people are making so much noise about this library is because of its ability to **translate** between one dialect and another - demonstrated below."
      ],
      "metadata": {
        "id": "XszDdyHz_ubF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlgpalodlVCG",
        "outputId": "a62f2001-63c3-41f0-cf34-d949d017d67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT id, load_date, CURRENT_TIMESTAMP AS \"todate\" /* this is unique to t-sql */, 'mystring' AS \"string\" FROM dbo.MyTable FETCH FIRST 1 /* this is unique to t-sql */ ROWS ONLY\n",
            "SELECT id, load_date, GETDATE() AS [todate] /* this is unique to t-sql */, 'mystring' AS [string] FROM dbo.MyTable FETCH FIRST 1 /* this is unique to t-sql */ ROWS ONLY\n"
          ]
        }
      ],
      "source": [
        "import sqlglot\n",
        "from sqlglot import dialects\n",
        "\n",
        "#I have a Query in Transact-SQL (TSQL)\n",
        "query1 = \"\"\"\n",
        "select\n",
        "  top 1 --this is unique to t-sql\n",
        "  id,\n",
        "  load_date,\n",
        "  getdate() [todate], --this is unique to t-sql\n",
        "  'mystring' [string]\n",
        "from dbo.MyTable\n",
        "\"\"\"\n",
        "\n",
        "#I want to run it on my identical Oracle Database\n",
        "#I send it in, specifying the Dialect it is Written in, and the Dialect I want it to be Transpiled To\n",
        "tsql2oracle = sqlglot.transpile(sql=query1, read=dialects.TSQL, write='oracle')\n",
        "#SQL Glot returns a List (that includes warnings and errors if there are any)\n",
        "print(tsql2oracle[0])\n",
        "\n",
        "#I can do it again, to get back to my original dialect\n",
        "oracle2tsql = sqlglot.transpile(sql=tsql2oracle[0], read='oracle', write='tsql')\n",
        "#SQL Glot returns the same query in a semantically similar form\n",
        "print(oracle2tsql[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's other stuff you can do too, such as providing a set of example tables, and then getting queries in a number of formats."
      ],
      "metadata": {
        "id": "pBG9HbpTxsok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlglot import select, condition\n",
        "\n",
        "# Here we can create arbitrary bits of code and slap them together\n",
        "where = condition(\"Load_Date between CURRENT_TIMESTAMP() - 1 and CURRENT_TIMESTAMP()\").and_(\"id >= 10\")\n",
        "queryString = select(\"*\").from_(\"MyTable\").where(where).sql()\n",
        "print('Sqlglot generated query in ANSI format')\n",
        "print(queryString)\n",
        "print('\\n')\n",
        "#and then we can transpile that!?  But hey, it didn't really do anything?!\n",
        "output = sqlglot.transpile( sql=queryString, read=None, write='tsql' )\n",
        "print('Transpiled to Transact-SQL')\n",
        "print(output[0])\n",
        "#the default dialect is ANSI SQL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwIQLa1kyco-",
        "outputId": "149f1206-dac8-4794-b727-c752f0dc833c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sqlglot generated query in ANSI format\n",
            "SELECT * FROM MyTable WHERE Load_Date BETWEEN CURRENT_TIMESTAMP() - 1 AND CURRENT_TIMESTAMP() AND id >= 10\n",
            "\n",
            "\n",
            "Transpiled to Transact-SQL\n",
            "SELECT * FROM MyTable WHERE Load_Date BETWEEN GETDATE() - 1 AND GETDATE() AND id >= 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This sounds great but how does it actually do that?*\n",
        "\n",
        "The secret sauce is in a concept call the **AST or Abstract Syntax Tree**.  ASTs are typically used in computer science to map out a [program flow](https://en.wikipedia.org/wiki/Abstract_syntax_tree#/media/File:Abstract_syntax_tree_for_Euclidean_algorithm.svg).  They are called **abstract** because the structural elements of the program are extracted from the source code and represented as a **tree**.\n",
        "\n",
        "The value that **sqlglot** adds is to parse SQL queries into an AST, which can then be used to identify portions of the query that might be different from dialect to dialect.\n",
        "\n",
        "SQLglot's documentation calls out three main parts of this library:\n",
        "* **Tokenizer**: Converts raw code into a sequence of “tokens”, one for each word/symbol\n",
        "* **Parser**: Converts sequence of tokens into an abstract syntax tree representing the semantics of the raw code\n",
        "* **Generator**: Converts an abstract syntax tree into SQL code"
      ],
      "metadata": {
        "id": "IZh1PuewlBI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlglot import tokenize\n",
        "#the tokenize method converts a query string into a list of expressions, categorizing the tokens.\n",
        "sql = \"\"\"\n",
        "select\n",
        "  bar.a,\n",
        "  baz.b + 1 as b\n",
        "from bar\n",
        "join baz\n",
        "on baz.a = bar.a\n",
        "\"\"\"\n",
        "tokens = tokenize(sql)\n",
        "for token in tokens:\n",
        "    print(token)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeY1JGMrVYwx",
        "outputId": "08eefa6c-d52d-486a-f66d-3cbefb43be9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Token token_type: TokenType.SELECT, text: select, line: 2, col: 6, start: 1, end: 6, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: bar, line: 3, col: 4, start: 10, end: 12, comments: []>\n",
            "<Token token_type: TokenType.DOT, text: ., line: 3, col: 5, start: 13, end: 13, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: a, line: 3, col: 6, start: 14, end: 14, comments: []>\n",
            "<Token token_type: TokenType.COMMA, text: ,, line: 3, col: 7, start: 15, end: 15, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: baz, line: 4, col: 4, start: 19, end: 21, comments: []>\n",
            "<Token token_type: TokenType.DOT, text: ., line: 4, col: 5, start: 22, end: 22, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: b, line: 4, col: 6, start: 23, end: 23, comments: []>\n",
            "<Token token_type: TokenType.PLUS, text: +, line: 4, col: 8, start: 25, end: 25, comments: []>\n",
            "<Token token_type: TokenType.NUMBER, text: 1, line: 4, col: 10, start: 27, end: 27, comments: []>\n",
            "<Token token_type: TokenType.ALIAS, text: as, line: 4, col: 13, start: 29, end: 30, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: b, line: 4, col: 15, start: 32, end: 32, comments: []>\n",
            "<Token token_type: TokenType.FROM, text: from, line: 5, col: 4, start: 34, end: 37, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: bar, line: 5, col: 8, start: 39, end: 41, comments: []>\n",
            "<Token token_type: TokenType.JOIN, text: join, line: 6, col: 4, start: 43, end: 46, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: baz, line: 6, col: 8, start: 48, end: 50, comments: []>\n",
            "<Token token_type: TokenType.ON, text: on, line: 7, col: 2, start: 52, end: 53, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: baz, line: 7, col: 6, start: 55, end: 57, comments: []>\n",
            "<Token token_type: TokenType.DOT, text: ., line: 7, col: 7, start: 58, end: 58, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: a, line: 7, col: 8, start: 59, end: 59, comments: []>\n",
            "<Token token_type: TokenType.EQ, text: =, line: 7, col: 10, start: 61, end: 61, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: bar, line: 7, col: 14, start: 63, end: 65, comments: []>\n",
            "<Token token_type: TokenType.DOT, text: ., line: 7, col: 15, start: 66, end: 66, comments: []>\n",
            "<Token token_type: TokenType.VAR, text: a, line: 7, col: 16, start: 67, end: 67, comments: []>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlglot import parse_one\n",
        "\n",
        "#in the abstract syntax tree the tokens are nested\n",
        "ast = parse_one(sql)\n",
        "\n",
        "print(repr(ast))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1GF0AdquTFF",
        "outputId": "3028bd01-acac-42ba-b858-4c4344f3ea06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select(\n",
            "  expressions=[\n",
            "    Column(\n",
            "      this=Identifier(this=a, quoted=False),\n",
            "      table=Identifier(this=bar, quoted=False)),\n",
            "    Alias(\n",
            "      this=Add(\n",
            "        this=Column(\n",
            "          this=Identifier(this=b, quoted=False),\n",
            "          table=Identifier(this=baz, quoted=False)),\n",
            "        expression=Literal(this=1, is_string=False)),\n",
            "      alias=Identifier(this=b, quoted=False))],\n",
            "  from=From(\n",
            "    this=Table(\n",
            "      this=Identifier(this=bar, quoted=False))),\n",
            "  joins=[\n",
            "    Join(\n",
            "      this=Table(\n",
            "        this=Identifier(this=baz, quoted=False)),\n",
            "      on=EQ(\n",
            "        this=Column(\n",
            "          this=Identifier(this=a, quoted=False),\n",
            "          table=Identifier(this=baz, quoted=False)),\n",
            "        expression=Column(\n",
            "          this=Identifier(this=a, quoted=False),\n",
            "          table=Identifier(this=bar, quoted=False))))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQLglot also includes an optimizer, that will check the AST against a set of standardized rules.  Some of these include:\n",
        "* fully qualifying tables and columns\n",
        "* simplifying\n",
        "* normalizing\n",
        "* unnesting subqueries\n",
        "\n",
        "[***There are 17 validation rules in total.***](https://github.com/tobymao/sqlglot/tree/main/sqlglot/optimizer)"
      ],
      "metadata": {
        "id": "ms4bWoY2bCJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlglot.optimizer import optimize\n",
        "\n",
        "opt_ast = optimize(\n",
        "    ast,\n",
        "    schema={\n",
        "        \"bar\":{\"a\":\"int\",\"b\":\"int\",\"c\":\"int\"},\n",
        "        \"baz\":{\"a\":\"int\",\"b\":\"int\",\"c\":\"int\"},\n",
        "    }\n",
        "    )\n",
        "print(repr(opt_ast))\n",
        "print('\\n')\n",
        "print(opt_ast.sql())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OYmeCCOV14p",
        "outputId": "e7d3970c-9a6d-4f82-8cb1-a8a6d9082cc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select(\n",
            "  expressions=[\n",
            "    Alias(\n",
            "      this=Column(\n",
            "        this=Identifier(this=a, quoted=True),\n",
            "        table=Identifier(this=bar, quoted=True),\n",
            "        _type=DataType(this=Type.INT, nested=False)),\n",
            "      alias=Identifier(this=a, quoted=True, _type=DataType(this=Type.UNKNOWN)),\n",
            "      _type=DataType(this=Type.INT, nested=False)),\n",
            "    Alias(\n",
            "      this=Add(\n",
            "        this=Column(\n",
            "          this=Identifier(this=b, quoted=True),\n",
            "          table=Identifier(this=baz, quoted=True),\n",
            "          _type=DataType(this=Type.INT, nested=False)),\n",
            "        expression=Literal(this=1, is_string=False, _type=DataType(this=Type.INT)),\n",
            "        _type=DataType(this=Type.INT)),\n",
            "      alias=Identifier(this=b, quoted=True, _type=DataType(this=Type.UNKNOWN)),\n",
            "      _type=DataType(this=Type.INT))],\n",
            "  from=From(\n",
            "    this=Table(\n",
            "      this=Identifier(this=bar, quoted=True, _type=DataType(this=Type.UNKNOWN)),\n",
            "      alias=TableAlias(\n",
            "        this=Identifier(this=bar, quoted=True, _type=DataType(this=Type.UNKNOWN)),\n",
            "        _type=DataType(this=Type.UNKNOWN)),\n",
            "      _type=DataType(this=Type.UNKNOWN)),\n",
            "    _type=DataType(this=Type.UNKNOWN)),\n",
            "  joins=[\n",
            "    Join(\n",
            "      this=Table(\n",
            "        this=Identifier(this=baz, quoted=True, _type=DataType(this=Type.UNKNOWN)),\n",
            "        alias=TableAlias(\n",
            "          this=Identifier(this=baz, quoted=True, _type=DataType(this=Type.UNKNOWN)),\n",
            "          _type=DataType(this=Type.UNKNOWN)),\n",
            "        _type=DataType(this=Type.UNKNOWN)),\n",
            "      on=EQ(\n",
            "        this=Column(\n",
            "          this=Identifier(this=a, quoted=True),\n",
            "          table=Identifier(this=bar, quoted=True),\n",
            "          _type=DataType(this=Type.INT, nested=False)),\n",
            "        expression=Column(\n",
            "          this=Identifier(this=a, quoted=True),\n",
            "          table=Identifier(this=baz, quoted=True),\n",
            "          _type=DataType(this=Type.INT, nested=False)),\n",
            "        _type=DataType(this=Type.BOOLEAN)),\n",
            "      _type=DataType(this=Type.UNKNOWN))],\n",
            "  _type=DataType(this=Type.UNKNOWN))\n",
            "\n",
            "\n",
            "SELECT \"bar\".\"a\" AS \"a\", \"baz\".\"b\" + 1 AS \"b\" FROM \"bar\" AS \"bar\" JOIN \"baz\" AS \"baz\" ON \"bar\".\"a\" = \"baz\".\"a\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQLglot can be used for Optimization and Validation, provided that it is aware of the database schemas in question.\n"
      ],
      "metadata": {
        "id": "cPpei1vM-Nau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlglot import dialects\n",
        "tsql2oracle = sqlglot.transpile(sql=query1,read='tsql', write='oracle')\n",
        "print(tsql2oracle[0])\n",
        "print('\\n')\n",
        "\n",
        "oracle2tsql = sqlglot.transpile(sql=query1, read='oracle', write='tsql')\n",
        "print(oracle2tsql[0])\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yadj_mQOM2SI",
        "outputId": "de00464d-36c8-44b7-c5d9-b5297087b172"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT id, load_date, CURRENT_TIMESTAMP AS \"todate\" /* this is unique to t-sql */, 'mystring' AS \"string\" FROM dbo.MyTable FETCH FIRST 1 /* this is unique to t-sql */ ROWS ONLY\n",
            "\n",
            "\n",
            "SELECT TOP 1 /* this is unique to t-sql */ id, load_date, GETDATE()[todate] /* this is unique to t-sql */, 'mystring'[string] FROM dbo.MyTable\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from the above, once we are in an ANSI SQL form, we don't always keep the spacing, and the comments are preserved as multiline comments.\n",
        "\n",
        "*The github often uses the phrase **best effort basis** when describing the preservation of spacing and comments*.  \n",
        "\n",
        "Still if you have **A LOT** of sql queries that need to go from **a sql dialect** ==> **b sql dialect**, this would not be a bad way to identify the parts that are problematic."
      ],
      "metadata": {
        "id": "7oLi6kcf8DJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another potential use from this library is enumerating the differences between two somewhat similar queries.  See below, we combine the **diff** method with the **parse_one** method to get a list of things we would need to do to change **sql a** ==> **sql b**"
      ],
      "metadata": {
        "id": "WTM561J3_ZOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqla = \"select a, b from baz\"\n",
        "sqlb = \"select b, c from bar join baz on baz.a = bar.a\"\n",
        "\n",
        "diff = sqlglot.diff( parse_one(sqla), parse_one(sqlb) )\n",
        "print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3kSNPq--KwL",
        "outputId": "4ddc6843-6b48-43ca-fc77-38df90d4df4b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Remove(expression=Select(\n",
            "  expressions=[\n",
            "    Column(\n",
            "      this=Identifier(this=a, quoted=False)),\n",
            "    Column(\n",
            "      this=Identifier(this=b, quoted=False))],\n",
            "  from=From(\n",
            "    this=Table(\n",
            "      this=Identifier(this=baz, quoted=False))))), Remove(expression=Column(\n",
            "  this=Identifier(this=a, quoted=False))), Remove(expression=From(\n",
            "  this=Table(\n",
            "    this=Identifier(this=baz, quoted=False)))), Insert(expression=Select(\n",
            "  expressions=[\n",
            "    Column(\n",
            "      this=Identifier(this=b, quoted=False)),\n",
            "    Column(\n",
            "      this=Identifier(this=c, quoted=False))],\n",
            "  from=From(\n",
            "    this=Table(\n",
            "      this=Identifier(this=bar, quoted=False))),\n",
            "  joins=[\n",
            "    Join(\n",
            "      this=Table(\n",
            "        this=Identifier(this=baz, quoted=False)),\n",
            "      on=EQ(\n",
            "        this=Column(\n",
            "          this=Identifier(this=a, quoted=False),\n",
            "          table=Identifier(this=baz, quoted=False)),\n",
            "        expression=Column(\n",
            "          this=Identifier(this=a, quoted=False),\n",
            "          table=Identifier(this=bar, quoted=False))))])), Insert(expression=Column(\n",
            "  this=Identifier(this=c, quoted=False))), Insert(expression=From(\n",
            "  this=Table(\n",
            "    this=Identifier(this=bar, quoted=False)))), Insert(expression=Join(\n",
            "  this=Table(\n",
            "    this=Identifier(this=baz, quoted=False)),\n",
            "  on=EQ(\n",
            "    this=Column(\n",
            "      this=Identifier(this=a, quoted=False),\n",
            "      table=Identifier(this=baz, quoted=False)),\n",
            "    expression=Column(\n",
            "      this=Identifier(this=a, quoted=False),\n",
            "      table=Identifier(this=bar, quoted=False))))), Insert(expression=Table(\n",
            "  this=Identifier(this=bar, quoted=False))), Insert(expression=EQ(\n",
            "  this=Column(\n",
            "    this=Identifier(this=a, quoted=False),\n",
            "    table=Identifier(this=baz, quoted=False)),\n",
            "  expression=Column(\n",
            "    this=Identifier(this=a, quoted=False),\n",
            "    table=Identifier(this=bar, quoted=False)))), Insert(expression=Column(\n",
            "  this=Identifier(this=a, quoted=False),\n",
            "  table=Identifier(this=baz, quoted=False))), Insert(expression=Column(\n",
            "  this=Identifier(this=a, quoted=False),\n",
            "  table=Identifier(this=bar, quoted=False))), Keep(source=Column(\n",
            "  this=Identifier(this=b, quoted=False)), target=Column(\n",
            "  this=Identifier(this=b, quoted=False))), Keep(source=Table(\n",
            "  this=Identifier(this=baz, quoted=False)), target=Table(\n",
            "  this=Identifier(this=baz, quoted=False)))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I am working with a Database that is Esoteric or Not Super Popular\n",
        "## How do I write my own dialect?\n",
        "\n",
        "Dialects are just .py files that are imported at runtime.  You can see them in the github under [/dialects](https://github.com/tobymao/sqlglot/tree/main/sqlglot/dialects).  You can two one of the following:\n",
        "\n",
        "\n",
        "1.   Contribute to SQLglot by writing Dialect Files\n",
        "2.   Create without Sharing *(by writing your own dialect and inserting locally)*\n",
        "\n",
        "Here are the kinds of things that are in the **tsql.py** dialect file:\n",
        "* Date & Time Formatting *(literals and expressions)*\n",
        "* Date & Number Defaults *(such as 1900-01-01)*\n",
        "* Custom Database functions *(such as EOMONTH() or STRING_AGG())*\n",
        "* Custom Formats for Common Table Expressions (CTEs) and Subqueries\n",
        "* Data Type Mapping\n",
        "* Special **TOKENS** that don't appear in other languages\n",
        "* Database Specific Compiler Hints\n",
        "\n",
        "## Advice:  \n",
        "If you're going to try and write a custom dialect file, you should know that dialect REALLY WELL\n",
        "\n",
        "## Takeaways:\n",
        "**This library does not replace expertise!**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xLJ7NKoAUGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More to Follow\n",
        "\n",
        "At work we are eventually going to replace **Oracle** databases with **Snowflake** as a data warehousing system of record, and so eventually I will be able to do a follow up talk where I describe how it went.\n",
        "\n",
        "**sqlglot** has support for oracle and snowflake systems, and so for queries and views there will be opportunity to use this library to save time."
      ],
      "metadata": {
        "id": "XjLR2BruKLzb"
      }
    }
  ]
}